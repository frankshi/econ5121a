<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>12 Generalized Method of Moments | Econ5121</title>
<meta name="author" content="Zhentao Shi">
<meta name="description" content="Generalized method of moments (GMM) (Hansen 1982) is an estimation principle that extends method of moments. It seeks the parameter value that minimizes a quadratic form of the moments. It is...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="12 Generalized Method of Moments | Econ5121">
<meta property="og:type" content="book">
<meta property="og:description" content="Generalized method of moments (GMM) (Hansen 1982) is an estimation principle that extends method of moments. It seeks the parameter value that minimizes a quadratic form of the moments. It is...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="12 Generalized Method of Moments | Econ5121">
<meta name="twitter:description" content="Generalized method of moments (GMM) (Hansen 1982) is an estimation principle that extends method of moments. It seeks the parameter value that minimizes a quadratic form of the moments. It is...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/_Alice-0.4.1/font.css" rel="stylesheet">
<link href="libs/_DM%20Mono-0.4.1/font.css" rel="stylesheet">
<link href="libs/_Montserrat-0.4.1/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Econ5121</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Preface</a></li>
<li><a class="" href="probability.html"><span class="header-section-number">2</span> Probability</a></li>
<li><a class="" href="conditional-expectation.html"><span class="header-section-number">3</span> Conditional Expectation</a></li>
<li><a class="" href="least-squares-linear-algebra.html"><span class="header-section-number">4</span> Least Squares: Linear Algebra</a></li>
<li><a class="" href="least-squares-finite-sample-theory.html"><span class="header-section-number">5</span> Least Squares: Finite Sample Theory</a></li>
<li><a class="" href="basic-asymptotic-theory.html"><span class="header-section-number">6</span> Basic Asymptotic Theory</a></li>
<li><a class="" href="asymptotic-properties-of-least-squares.html"><span class="header-section-number">7</span> Asymptotic Properties of Least Squares</a></li>
<li><a class="" href="asymptotic-properties-of-mle.html"><span class="header-section-number">8</span> Asymptotic Properties of MLE</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">9</span> Hypothesis Testing</a></li>
<li><a class="" href="panel-data.html"><span class="header-section-number">10</span> Panel Data</a></li>
<li><a class="" href="endogeneity.html"><span class="header-section-number">11</span> Endogeneity</a></li>
<li><a class="active" href="generalized-method-of-moments.html"><span class="header-section-number">12</span> Generalized Method of Moments</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/zhentaoshi/Econ5121A">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="generalized-method-of-moments" class="section level1" number="12">
<h1>
<span class="header-section-number">12</span> Generalized Method of Moments<a class="anchor" aria-label="anchor" href="#generalized-method-of-moments"><i class="fas fa-link"></i></a>
</h1>
<p><em>Generalized method of moments</em> (GMM) <span class="citation">(<a href="generalized-method-of-moments.html#ref-hansen1982large" role="doc-biblioref">Hansen 1982</a>)</span> is an
estimation principle that extends <em>method of moments</em>. It seeks the
parameter value that minimizes a quadratic form of the moments. It is
particularly useful in estimating structural economic models in which
moment conditions can be derived from underlying economic theory. GMM
emerges as one of the most popular estimators in modern econometrics. It
includes conventional methods like the two-stage least squares (2SLS)
and the three-stage least square as special cases.</p>
<div id="instrumental-regression" class="section level2" number="12.1">
<h2>
<span class="header-section-number">12.1</span> Instrumental Regression<a class="anchor" aria-label="anchor" href="#instrumental-regression"><i class="fas fa-link"></i></a>
</h2>
<p>We first discuss estimation in a linear single structural equation
<span class="math display">\[y_{i}=x_{i}'\beta+\epsilon_{i}\]</span> with <span class="math inline">\(K\)</span> regressors. Identification
is a prerequisite for structural estimation. From now on we always
assume that the model is identified: there is an <span class="math inline">\(L\times1\)</span> vector of
instruments <span class="math inline">\(z_{i}\)</span> such that
<span class="math inline">\(\mathbb{E}\left[z_{i}\epsilon_{i}\right]=0_{L}\)</span> and
<span class="math inline">\(\Sigma:=\mathbb{E}\left[z_{i}x_{i}'\right]\)</span> is of full column rank.
Denote <span class="math inline">\(\beta_{0}\)</span> as the root of the equation
<span class="math inline">\(E\left[z_{i}\left(y_{i}-x_{i}'\beta\right)\right]=0_{L}\)</span>, which is
uniquely identified.</p>
<div id="just-identification" class="section level3" number="12.1.1">
<h3>
<span class="header-section-number">12.1.1</span> Just-identification<a class="anchor" aria-label="anchor" href="#just-identification"><i class="fas fa-link"></i></a>
</h3>
<p>When <span class="math inline">\(L=K\)</span>, the instrumental regression model is <em>just-identified</em>, or
<em>exactly identified</em>. The orthogonality condition implies
<span class="math display">\[\Sigma\beta_{0}=\mathbb{E}\left[z_{i}y_{i}\right],\]</span> and we can solve
express <span class="math inline">\(\beta_{0}\)</span> as
<span class="math display">\[\beta_{0}=\Sigma^{-1}\mathbb{E}\left[z_{i}y_{i}\right]\label{eq:just_beta}\]</span>
in closed form.</p>
<p>The closed-form solution naturally motivates an estimator in which we
replace the population methods by the sample moments and this is a
method-of-moments estimator. Nevertheless, we postpone the discussion of
this estimator to the next section.</p>
</div>
<div id="over-identification" class="section level3" number="12.1.2">
<h3>
<span class="header-section-number">12.1.2</span> Over-identification<a class="anchor" aria-label="anchor" href="#over-identification"><i class="fas fa-link"></i></a>
</h3>
<p>When <span class="math inline">\(L&gt;K\)</span>, the model is <em>over-identified</em>. The orthogonality condition
still implies
<span class="math display">\[\Sigma\beta_{0}=\mathbb{E}\left[z_{i}y_{i}\right],\label{eq:moment2}\]</span>
but <span class="math inline">\(\Sigma\)</span> is not a square matrix so we cannot write <span class="math inline">\(\beta_{0}\)</span> as
that in (<a href="#eq:just_beta" reference-type="ref" reference="eq:just_beta"><span class="math display">\[eq:just\_beta\]</span></a>). In order to express <span class="math inline">\(\beta_{0}\)</span> explicitly,
we define a criterion function
<span class="math display">\[Q\left(\beta\right)=\mathbb{E}\left[z_{i}\left(y_{i}-x_{i}\beta\right)\right]'W\mathbb{E}\left[z_{i}\left(y_{i}-x_{i}\beta\right)\right],\]</span>
where <span class="math inline">\(W\)</span> is an <span class="math inline">\(L\times L\)</span> positive-definite non-random symmetric
matrix. (The choice of <span class="math inline">\(W\)</span> will be discussed soon.) Because of the
quadratic form, <span class="math inline">\(Q\left(\beta\right)\geq0\)</span> for all <span class="math inline">\(\beta\)</span>.
Identification indicates that <span class="math inline">\(Q\left(\beta\right)=0\)</span> if and only if
<span class="math inline">\(\beta=\beta_{0}\)</span>. Therefore we conclude
<span class="math display">\[\beta_{0}=\arg\min_{\beta}Q\left(\beta\right)\]</span> is the unique
minimizer. Since <span class="math inline">\(Q\left(\beta\right)\)</span> is a smooth function of <span class="math inline">\(\beta\)</span>,
the minimizer <span class="math inline">\(\beta_{0}\)</span> can be characterized by the first-order
condition
<span class="math display">\[0_{K}=\frac{\partial}{\partial\beta}Q\left(\beta_{0}\right)=-2\Sigma'W\mathbb{E}\left[z_{i}\left(y_{i}-x_{i}\beta_{0}\right)\right]\]</span>
Rearranging the above equation, we have
<span class="math display">\[\Sigma'W\Sigma\beta_{0}=\Sigma'W\mathbb{E}\left[z_{i}y_{i}\right].\]</span>
Under the rank condition <span class="math inline">\(\Sigma'W\Sigma\)</span> is invertible so that we can
solve
<span class="math display">\[\beta_{0}=\left(\Sigma'W\Sigma\right)^{-1}\Sigma'W\mathbb{E}\left[z_{i}y_{i}\right].\label{eq:over_beta}\]</span>
Because we have more moments (<span class="math inline">\(L\)</span>) than the number of unknown parameters
(<span class="math inline">\(K\)</span>), we call it the <em>generalized</em> method of moments.</p>
<p>The above equation can be derived by pre-multiplying <span class="math inline">\(\Sigma'W\)</span> on the
both sides of (<a href="#eq:moment2" reference-type="ref" reference="eq:moment2"><span class="math display">\[eq:moment2\]</span></a>) without referring to the minimization problem.</p>
<p>Although we separate the discussion of the just-identified case and the
over-identified case, the latter
(<a href="#eq:over_beta" reference-type="ref" reference="eq:over_beta"><span class="math display">\[eq:over\_beta\]</span></a>) actually takes
(<a href="#eq:just_beta" reference-type="ref" reference="eq:just_beta"><span class="math display">\[eq:just\_beta\]</span></a>) as a special case. In this sense, GMM is
genuine generalization of the method of moments. to see this point,
notice that when <span class="math inline">\(L=K\)</span>, given any <span class="math inline">\(W\)</span> we have <span class="math display">\[\begin{aligned}
\beta_{0} &amp; =\left(\Sigma'W\Sigma\right)^{-1}\Sigma'W\mathbb{E}\left[z_{i}y_{i}\right]=\Sigma^{-1}W^{-1}(\Sigma')^{-1}\Sigma'W\mathbb{E}\left[z_{i}y_{i}\right]\\
&amp; =\Sigma^{-1}W^{-1}W\mathbb{E}\left[z_{i}y_{i}\right]=\Sigma^{-1}\mathbb{E}\left[z_{i}y_{i}\right],\end{aligned}\]</span>
as <span class="math inline">\(\Sigma\)</span> is a square matrix. That is to say, in the just-identified
case <span class="math inline">\(W\)</span> plays no role because any choices of <span class="math inline">\(W\)</span> lead to the same
explicit solution of <span class="math inline">\(\beta_{0}\)</span>.</p>
</div>
</div>
<div id="gmm-estimator" class="section level2" number="12.2">
<h2>
<span class="header-section-number">12.2</span> GMM Estimator<a class="anchor" aria-label="anchor" href="#gmm-estimator"><i class="fas fa-link"></i></a>
</h2>
<p>In practice, we use the sample moments to replace the corresponding
population moments. The GMM estimator mimics its population formula.
<span class="math display">\[\begin{aligned}
\widehat{\beta} &amp; = &amp; \left(\frac{1}{n}\sum x_{i}z_{i}'W\frac{1}{n}\sum z_{i}x_{i}'\right)^{-1}\frac{1}{n}\sum x_{i}z_{i}'W\frac{1}{n}\sum z_{i}y_{i}\\
&amp; = &amp; \left(\frac{X'Z}{n}W\frac{Z'X}{n}\right)^{-1}\frac{X'Z}{n}W\frac{Z'y}{n}\\
&amp; = &amp; \left(X'ZWZ'X\right)^{-1}X'ZWZ'y.\end{aligned}\]</span> Under
just-identification, this expression includes the 2SLS estimator
<span class="math display">\[\hat{\beta}=\left(\frac{Z'X}{n}\right)^{-1}\frac{Z'y}{n}=\left(Z'X\right)^{-1}Z'y\]</span>
as a special case.</p>
<p>The same GMM estimator <span class="math inline">\(\hat{\beta}\)</span> can be obtained by minimizing
<span class="math display">\[Q_{n}\left(\beta\right)=\left[\frac{1}{n}\sum_{i=1}^{n}z_{i}\left(y_{i}-x_{i}\beta\right)\right]'W\left[\frac{1}{n}\sum_{i=1}^{n}z_{i}\left(y_{i}-x_{i}\beta\right)\right]=\frac{\left(y-X\beta\right)'Z}{n}W\frac{Z'\left(y-X\beta\right)}{n},\]</span>
or more concisely
<span class="math inline">\(\hat{\beta}=\arg\min_{\beta}\left(y-X\beta\right)'ZWZ'\left(y-X\beta\right).\)</span></p>
<p>Now we check the asymptotic properties of <span class="math inline">\(\widehat{\beta}\)</span>. A few
assumptions are in order.</p>
<p><span class="math inline">\(Z'X/n\stackrel{\mathrm{p}}{\to}\Sigma\)</span> and
<span class="math inline">\(Z'\epsilon/n\stackrel{\mathrm{p}}{\to}0_{L}\)</span>.</p>
<p>A.1 assumes that we can apply a law of large numbers, so that that the
sample moments <span class="math inline">\(Z'X/n\)</span> and <span class="math inline">\(Z'\epsilon/n\)</span> converge in probability to
their population counterparts.</p>
<p>Under Assumption A.1, <span class="math inline">\(\widehat{\beta}\)</span> is consistent.</p>
<p>The step is similar to the consistency proof of OLS. <span class="math display">\[\begin{aligned}
\widehat{\beta} &amp; =\left(X'ZWZ'X\right)^{-1}X'ZWZ'\left(X'\beta_{0}+\epsilon\right)\\
&amp; =\beta_{0}+\left(\frac{X'Z}{n}W\frac{Z'X}{n}\right)^{-1}\frac{X'Z}{n}W\frac{Z'\epsilon}{n}\\
&amp; \stackrel{\mathrm{p}}{\to}\beta_{0}+\left(\Sigma'W\Sigma\right)^{-1}\Sigma'W0=\beta_{0}.\qedhere\end{aligned}\]</span></p>
<p>To check asymptotic normality, we assume that a central limit theorem
can be applied.</p>
<p><span class="math inline">\(\frac{1}{\sqrt{n}}\sum_{i=1}^{n}z_{i}\epsilon_{i}\stackrel{d}{\to}N\left(0_{L},\Omega\right)\)</span>,
where <span class="math inline">\(\Omega=\mathbb{E}\left[z_{i}z_{i}'\epsilon_{i}^{2}\right].\)</span></p>
<p>Under Assumptions A.1 and A.2,
<span class="math display">\[\sqrt{n}\left(\widehat{\beta}-\beta_{0}\right)\stackrel{d}{\to}N\left(0_{K},\left(\Sigma'W\Sigma\right)^{-1}\Sigma'W\Omega W\Sigma\left(\Sigma'W\Sigma\right)^{-1}\right).\label{eq:normality}\]</span></p>
<p>Multiply <span class="math inline">\(\widehat{\beta}-\beta_{0}\)</span> by the scaling factor <span class="math inline">\(\sqrt{n}\)</span>,
<span class="math display">\[\sqrt{n}\left(\widehat{\beta}-\beta_{0}\right)=\left(\frac{X'Z}{n}W\frac{Z'X}{n}\right)^{-1}\frac{X'Z}{n}W\frac{Z'\epsilon}{\sqrt{n}}=\left(\frac{X'Z}{n}W\frac{Z'X}{n}\right)^{-1}\frac{X'Z}{n}W\frac{1}{\sqrt{n}}\sum_{i=1}^{n}z_{i}'\epsilon_{i}.\]</span>
The conclusion follows by the Slutsky’s theorem as
<span class="math display">\[\frac{X'Z}{n}W\frac{Z'X}{n}\stackrel{\mathrm{p}}{\to}\Sigma'W\Sigma\]</span>
and
<span class="math display">\[\frac{X'Z}{n}W\frac{1}{\sqrt{n}}\sum z_{i}'\epsilon_{i}\stackrel{d}{\to}\Sigma'W\times N\left(0,\Omega\right)\sim N\left(0,\Sigma'W\Omega W\Sigma\right).\qedhere\]</span></p>
<div id="efficient-gmm" class="section level3" number="12.2.1">
<h3>
<span class="header-section-number">12.2.1</span> Efficient GMM<a class="anchor" aria-label="anchor" href="#efficient-gmm"><i class="fas fa-link"></i></a>
</h3>
<p>It is clear from (<a href="#eq:normality" reference-type="ref" reference="eq:normality"><span class="math display">\[eq:normality\]</span></a>) that the GMM estimator’s asymptotic variance
depends on the choice of <span class="math inline">\(W\)</span>. Which <span class="math inline">\(W\)</span> makes the asymptotic variance as
small as possible? The answer is <span class="math inline">\(W=\Omega^{-1}\)</span>, under which the
efficient asymptotic variance is
<span class="math display">\[\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}\Sigma'\Omega^{-1}\Omega\Omega^{-1}\Sigma\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}=\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}.\]</span></p>
<p>For any positive definite symmetric matrix <span class="math inline">\(W\)</span>, the difference
<span class="math display">\[\left(\Sigma'W\Sigma\right)^{-1}\Sigma'W\Omega W\Sigma\left(\Sigma'W\Sigma\right)^{-1}-\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}\]</span>
is positive semi-definite.</p>
<p>To simplify notation, denote
<span class="math inline">\(A:=W\Sigma\left(\Sigma'W\Sigma\right)^{-1}\)</span> and
<span class="math inline">\(B:=\Omega^{-1}\Sigma\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}\)</span> and
then the difference of the two matrices becomes <span class="math display">\[\begin{aligned}
&amp;  &amp; \left(\Sigma'W\Sigma\right)^{-1}\Sigma'W\Omega W\Sigma\left(\Sigma'W\Sigma\right)^{-1}-\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}\\
&amp; = &amp; A'\Omega A-B'\Omega B\\
&amp; = &amp; \left(A-B+B\right)'\Omega\left(A-B+B\right)-B'\Omega B\\
&amp; = &amp; \left(A-B\right)'\Omega\left(A-B\right)+\left(A-B\right)'\Omega B+B'\Omega\left(A-B\right).\end{aligned}\]</span>
Notice that <span class="math display">\[\begin{aligned}
B'\Omega A &amp; =\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}\Sigma'\Omega^{-1}\Omega W\Sigma\left(\Sigma'W\Sigma\right)^{-1}\\
&amp; =\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}\Sigma'W\Sigma\left(\Sigma'W\Sigma\right)^{-1}=\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}=B'\Omega B,\end{aligned}\]</span>
which implies <span class="math inline">\(B'\Omega\left(A-B\right)=0\)</span> and
<span class="math inline">\(\left(A-B\right)'\Omega B=0\)</span>. We thus conclude that
<span class="math display">\[\left(\Sigma'W\Sigma\right)^{-1}\Sigma'W\Omega W\Sigma\left(\Sigma'W\Sigma\right)^{-1}-\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}=\left(A-B\right)'\Omega\left(A-B\right)\]</span>
is positive semi-definite.</p>
</div>
<div id="two-step-gmm" class="section level3" number="12.2.2">
<h3>
<span class="header-section-number">12.2.2</span> Two-Step GMM<a class="anchor" aria-label="anchor" href="#two-step-gmm"><i class="fas fa-link"></i></a>
</h3>
<p>The <em>two-step GMM</em> is one way to construct a feasible efficient GMM
estimator.</p>
<ol style="list-style-type: decimal">
<li><p>Choose any valid <span class="math inline">\(W\)</span>, say <span class="math inline">\(W=I_{L}\)</span>, to get a consistent (but
inefficient in general) estimator
<span class="math inline">\(\hat{\beta}^{\sharp}=\hat{\beta}^{\sharp}\left(W\right)\)</span>. Save the
residual <span class="math inline">\(\widehat{\epsilon}_{i}=y_{i}-x_{i}'\hat{\beta}^{\sharp}\)</span>
and estimate the variance matrix
<span class="math inline">\(\widehat{\Omega}=\frac{1}{n}\sum z_{i}z_{i}'\widehat{\epsilon}_{i}^{2}.\)</span>
Notice that this <span class="math inline">\(\widehat{\Omega}\)</span> is a consistent for <span class="math inline">\(\Omega\)</span>.</p></li>
<li><p>Set <span class="math inline">\(W=\widehat{\Omega}^{-1}\)</span> and obtain the second estimator
<span class="math display">\[\widehat{\beta}^{\natural}=\widehat{\beta}^{\natural}(\widehat{\Omega}^{-1})=\left(X'Z\widehat{\Omega}^{-1}Z'X\right)^{-1}X'Z\widehat{\Omega}^{-1}Z'y.\]</span>
This second estimator is asymptotic efficient.</p></li>
</ol>
<p>Show that if <span class="math inline">\(\widehat{\Omega}\stackrel{p}{\to}\Omega\)</span>, then
<span class="math inline">\(\sqrt{n}\left(\widehat{\beta}^{\natural}(\widehat{\Omega}^{-1})-\widehat{\beta}\left(\Omega^{-1}\right)\right)\stackrel{p}{\to}0\)</span>.
In other words, the feasible estimator
<span class="math inline">\(\widehat{\beta}^{\natural}(\widehat{\Omega}^{-1})\)</span> is asymptotically
equivalent to the infeasible efficient estimator
<span class="math inline">\(\widehat{\beta}\left(\Omega^{-1}\right)\)</span>.</p>
</div>
<div id="two-stage-least-squares" class="section level3" number="12.2.3">
<h3>
<span class="header-section-number">12.2.3</span> Two Stage Least Squares<a class="anchor" aria-label="anchor" href="#two-stage-least-squares"><i class="fas fa-link"></i></a>
</h3>
<p>If we further assume conditional homoskedasticity
<span class="math inline">\(\mathbb{E}\left[\epsilon_{i}^{2}|z_{i}\right]=\sigma^{2}\)</span>, then
<span class="math display">\[\Omega=\mathbb{E}\left[z_{i}z_{i}'\epsilon_{i}^{2}\right]=\mathbb{E}\left[z_{i}z_{i}'\mathbb{E}\left[\epsilon_{i}^{2}|z_{i}\right]\right]=\sigma^{2}\mathbb{E}\left[z_{i}z_{i}'\right].\]</span>
In the first-step of the two-step GMM we can estimate the variance of
the error term by
<span class="math inline">\(\widehat{\sigma}^{2}=\frac{1}{n}\sum_{i=1}^{n}\widehat{\epsilon}_{i}^{2}\)</span>
and the variance matrix by
<span class="math inline">\(\widehat{\Omega}=\widehat{\sigma}^{2}\frac{1}{n}\sum_{i=1}^{n}z_{i}z_{i}'=\widehat{\sigma}^{2}Z'Z/n\)</span>.
When we plug this <span class="math inline">\(W=\widehat{\Omega}^{-1}\)</span> into the GMM estimator,
<span class="math display">\[\begin{aligned}
\widehat{\beta} &amp; = &amp; \left(X'Z\left(\widehat{\sigma}^{2}\frac{Z'Z}{n}\right)^{-1}Z'X\right)^{-1}X'Z\left(\widehat{\sigma}^{2}\frac{Z'Z}{n}\right)^{-1}Z'y\\
&amp; = &amp; \left(X'Z\left(Z'Z\right)^{-1}Z'X\right)^{-1}X'Z\left(Z'Z\right)^{-1}Z'y.\end{aligned}\]</span>
This is exactly the same expression of 2SLS for <span class="math inline">\(L&gt;K\)</span>. Therefore, 2SLS
can be viewed as a special case of GMM with the weighting matrix
<span class="math inline">\(\left(Z'Z/n\right)^{-1}\)</span>. Under conditional homoskedasticity, 2SLS is
the efficient estimator. 2SLS is inefficient in general cases of
heteroskedasticity, despite its popularity.</p>
<p>2SLS gets its name because it can be obtained using two steps: first
regress <span class="math inline">\(X\)</span> on all instruments <span class="math inline">\(Z\)</span>, and then regress <span class="math inline">\(y\)</span> on the fitted
value along with the included exogenous variables. However, 2SLS can
actually be obtained by one step using the above equation. It is a
special case of GMM.</p>
<p>If an efficient estimator is not too difficult to implement, an
econometric theorist would prefer the efficient estimator to an
inefficient estimator. The benefits of using the efficient estimator is
not limited to more accurate coefficient estimation. Many specification
tests, for example the <span class="math inline">\(J\)</span>-statistic we will introduce soon, count on
the efficient estimator to lead to a familiar <span class="math inline">\(\chi^{2}\)</span> distribution
under null hypotheses. Otherwise their null asymptotic distributions
will be non-standard and thereby critical values must be found by Monte
Carlo simulations.</p>
</div>
</div>
<div id="gmm-in-nonlinear-model" class="section level2" number="12.3">
<h2>
<span class="header-section-number">12.3</span> GMM in Nonlinear Model<a class="anchor" aria-label="anchor" href="#gmm-in-nonlinear-model"><i class="fas fa-link"></i></a>
</h2>
<p>The principle of GMM can be used in models where the parameter enters
the moment conditions nonlinearly. Let
<span class="math inline">\(g_{i}\left(\beta\right)=g\left(w_{i},\beta\right)\mapsto\mathbb{R}^{L}\)</span>
be a function of the data <span class="math inline">\(w_{i}\)</span> and the parameter <span class="math inline">\(\beta\)</span>. If economic
theory implies <span class="math inline">\(\mathbb{E}\left[g_{i}\left(\beta\right)\right]=0\)</span>, which
the statisticians call the <em>estimating equations</em>, we can write the GMM
population criterion function as
<span class="math display">\[Q\left(\beta\right)=\mathbb{E}\left[g_{i}\left(\beta\right)\right]'W\mathbb{E}\left[g_{i}\left(\beta\right)\right]\]</span></p>
<p>Nonlinear models nest the linear model as a special case. For the linear
IV model in the previous section, the data is
<span class="math inline">\(w_{i}=\left(y_{i},x_{i},z_{i}\right)\)</span>, and the moment function is
<span class="math inline">\(g\left(w_{i},\beta\right)=z_{i}'\left(y_{i}-x_{i}\beta\right)\)</span>.</p>
<p>In practice we use the sample moments to mimic the population moments in
the criterion function
<span class="math display">\[Q_{n}\left(\beta\right)=\left(\frac{1}{n}\sum_{i=1}^{n}g_{i}\left(\beta\right)\right)'W\left(\frac{1}{n}\sum_{i=1}^{n}g_{i}\left(\beta\right)\right).\]</span>
The GMM estimator is defined as
<span class="math display">\[\hat{\beta}=\arg\min_{\beta}Q_{n}\left(\beta\right).\]</span> In these
nonlinear models, a closed-form solution is in general unavailable,
while the asymptotic properties can still be established. We state these
asymptotic properties without proofs.</p>
<p>(a) If the model is identified, and
<span class="math display">\[\mathbb{P}\left\{ \sup_{\beta\in\mathcal{B}}\big|\frac{1}{n}\sum_{i=1}^{n}g_{i}\left(\beta\right)-\mathbb{E}\left[g_{i}\left(\beta\right)\right]\big|&gt;\varepsilon\right\} \to0\]</span>
for any constant <span class="math inline">\(\varepsilon&gt;0\)</span> where the parametric space
<span class="math inline">\(\mathcal{B}\)</span> is a closed set, then
<span class="math inline">\(\hat{\beta}\stackrel{\mathrm{p}}{\to}\beta.\)</span><br>
(b) If in addition
<span class="math inline">\(\frac{1}{\sqrt{n}}\sum_{i=1}^{n}g_{i}\left(\beta_{0}\right)\stackrel{d}{\to}N\left(0,\Omega\right)\)</span>
and
<span class="math inline">\(\Sigma=\mathbb{E}\left[\frac{\partial}{\partial\beta'}g_{i}\left(\beta_{0}\right)\right]\)</span>
is of full column rank, then
<span class="math display">\[\sqrt{n}\left(\hat{\beta}-\beta_{0}\right)\stackrel{d}{\to}N\left(0,\left(\Sigma'W\Sigma\right)^{-1}\left(\Sigma'W\Omega W\Sigma\right)\left(\Sigma'W\Sigma\right)^{-1}\right)\]</span>
where
<span class="math inline">\(\Omega=\mathbb{E}\left[g_{i}\left(\beta_{0}\right)g_{i}\left(\beta_{0}\right)'\right]\)</span>.<br>
(c) If we choose <span class="math inline">\(W=\Omega^{-1}\)</span>, then the GMM estimator is efficient,
and the asymptotic variance becomes
<span class="math inline">\(\left(\Sigma'\Omega^{-1}\Sigma\right)^{-1}\)</span>.</p>
<p>The list of assumptions in the above statement is incomplete. We only
lay out the key conditions but neglect some technical details.</p>
<p><span class="math inline">\(Q_{n}\left(\beta\right)\)</span> measures how close are the moments to zeros.
It can serve as a test statistic with proper scaling. Under the null
hypothesis <span class="math inline">\(\mathbb{E}\left[g_{i}\left(\beta\right)\right]=0_{L}\)</span>, this
Sargan-Hansen <span class="math inline">\(J\)</span>-test checks whether a moment condition is violated.
The test statistic is <span class="math display">\[\begin{aligned}
J\left(\widehat{\beta}\right) &amp; =nQ_{n}\left(\widehat{\beta}\right)=n\left(\frac{1}{n}\sum_{i=1}^{n}g_{i}\left(\widehat{\beta}\right)\right)'\widehat{\Omega}^{-1}\left(\frac{1}{n}\sum_{i=1}^{n}g_{i}\left(\widehat{\beta}\right)\right)\\
&amp; =\left(\frac{1}{\sqrt{n}}\sum_{i=1}^{n}g_{i}\left(\widehat{\beta}\right)\right)'\widehat{\Omega}^{-1}\left(\frac{1}{\sqrt{n}}\sum_{i=1}^{n}g_{i}\left(\widehat{\beta}\right)\right)\end{aligned}\]</span>
where <span class="math inline">\(\widehat{\Omega}\)</span> is a consistent estimator of <span class="math inline">\(\Omega\)</span>, and
<span class="math inline">\(\widehat{\beta}\)</span> is an efficient estimator, for example, the two-step
GMM estimator <span class="math inline">\(\widehat{\beta}^{\natural}(\widehat{\Omega}^{-1})\)</span>. This
statistic converges in distribution to a <span class="math inline">\(\chi^{2}\)</span> random variable with
degree of freedom <span class="math inline">\(L-K\)</span>. That is, under the null,
<span class="math display">\[J\left(\widehat{\beta}\right)\stackrel{d}{\to}\chi^{2}\left(L-K\right).\]</span>
If the null hypothesis is false, then the test statistic tends to be
large and it is more likely to reject the null.</p>
</div>
<div id="summary-10" class="section level2" number="12.4">
<h2>
<span class="header-section-number">12.4</span> Summary<a class="anchor" aria-label="anchor" href="#summary-10"><i class="fas fa-link"></i></a>
</h2>
<p>The popularity of GMM in econometrics comes from the fact that economic
theory is often not informative enough about the underlying parametric
relationship amongst the variables. Instead, many economic assumptions
suggest moment restrictions. From example, the <em>efficient market
hypothesis</em> postulates that the future price movement <span class="math inline">\(\Delta p_{t+1}\)</span>
cannot be predicted by available past information set <span class="math inline">\(\mathscr{I}_{t}\)</span>
so that <span class="math inline">\(\mathbb{E}\left[\Delta p_{t+1}|\mathscr{I}_{t}\right]=0\)</span>. It
implies that any functions of the variables in the information set
<span class="math inline">\(\mathscr{I}_{t}\)</span> are orthogonal to <span class="math inline">\(\Delta p_{t+1}\)</span>. A plethora of
moment conditions can be constructed in order to test the efficient
market hypothesis.</p>
<p>Conceptually simple though, GMM has many practical issues in reality.
There has been vast econometric literature about issues of GMM and their
remedies.</p>
<p><strong>Historical notes</strong>: 2SLS was attributed to <span class="citation">Theil (<a href="generalized-method-of-moments.html#ref-theil1953repeated" role="doc-biblioref">1953</a>)</span>. In the
linear IV model, the <span class="math inline">\(J\)</span>-statistic was proposed by
<span class="citation">Sargan (<a href="generalized-method-of-moments.html#ref-sargan1958estimation" role="doc-biblioref">1958</a>)</span>, and <span class="citation">Hansen (<a href="generalized-method-of-moments.html#ref-hansen1982large" role="doc-biblioref">1982</a>)</span> extended it to nonlinear
models.</p>
<p><strong>Further reading</strong>: The quadratic form of GMM makes it difficult to
accommodate many moments in the big data problems. <em>Empirical
likelihood</em> is an alternative estimator to GMM to estimate models
defined by moment restrictions. <span class="citation">Shi (<a href="generalized-method-of-moments.html#ref-shi2016econometric" role="doc-biblioref">2016</a>)</span> solves the
estimation problem of high-dimensional moments under the framework of
empirical likelihood.</p>
<p><code>Zhentao Shi. Dec 3, 2020.</code></p>

<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-chen2011nonlinear" class="csl-entry">
Chen, Xiaohong, Han Hong, and Denis Nekipelov. 2011. <span>“Nonlinear Models of Measurement Errors.”</span> <em>Journal of Economic Literature</em> 49 (4): 901–37.
</div>
<div id="ref-cover2006elements" class="csl-entry">
Cover, Thomas M, and Joy A. Thomas. 2006. <em>Elements of Information Theory (2nd Ed.)</em>. John Wiley &amp; Sons.
</div>
<div id="ref-davidson1994stochastic" class="csl-entry">
Davidson, James. 1994. <em>Stochastic Limit Theory: An Introduction for Econometricians</em>. Oxford University Press.
</div>
<div id="ref-doob1996development" class="csl-entry">
Doob, Joseph L. 1996. <span>“The Development of Rigor in Mathematical Probability (1900–1950).”</span> <em>The American Mathematical Monthly</em> 103 (7): 586–95.
</div>
<div id="ref-fricsh1934statistical" class="csl-entry">
Fricsh, R. 1934. <span>“Statistical Confluence Study.”</span> <em>Oslo: University Institute of Economics</em>.
</div>
<div id="ref-gow2016causal" class="csl-entry">
Gow, Ian D, David F Larcker, and Peter C Reiss. 2016. <span>“Causal Inference in Accounting Research.”</span> <em>Journal of Accounting Research</em> 54 (2): 477–523.
</div>
<div id="ref-haavelmo1943statistical" class="csl-entry">
Haavelmo, Trygve. 1943. <span>“The Statistical Implications of a System of Simultaneous Equations.”</span> <em>Econometrica, Journal of the Econometric Society</em>, 1–12.
</div>
<div id="ref-hansen1982large" class="csl-entry">
Hansen, Lars Peter. 1982. <span>“Large Sample Properties of Generalized Method of Moments Estimators.”</span> <em>Econometrica: Journal of the Econometric Society</em>, 1029–54.
</div>
<div id="ref-hsiao2014analysis" class="csl-entry">
Hsiao, Cheng. 2014. <em>Analysis of Panel Data</em>. 54. Cambridge University Press.
</div>
<div id="ref-lewbel2019identification" class="csl-entry">
Lewbel, Arthur. 2019. <span>“The Identification Zoo: Meanings of Identification in Econometrics.”</span> <em>Journal of Economic Literature</em> 57 (4): 835–903.
</div>
<div id="ref-lucas1976econometric" class="csl-entry">
Lucas, Robert E. 1976. <span>“Econometric Policy Evaluation: A Critique.”</span> In <em>Carnegie-Rochester Conference Series on Public Policy</em>, 1:19–46. 1.
</div>
<div id="ref-newey1994large" class="csl-entry">
Newey, KW, and Daniel McFadden. 1994. <span>“Large Sample Estimation and Hypothesis.”</span> <em>Handbook of Econometrics, IV, Edited by RF Engle and DL McFadden</em>, 2112–2245.
</div>
<div id="ref-pearl2018book" class="csl-entry">
Pearl, Judea, and Dana Mackenzie. 2018. <em>The Book of Why: The New Science of Cause and Effect</em>. Basic Books.
</div>
<div id="ref-phillips1983exact" class="csl-entry">
Phillips, Peter CB. 1983. <span>“Exact Small Sample Theory in the Simultaneous Equations Model.”</span> <em>Handbook of Econometrics</em> 1: 449–516.
</div>
<div id="ref-sargan1958estimation" class="csl-entry">
Sargan, John D. 1958. <span>“The Estimation of Economic Relationships Using Instrumental Variables.”</span> <em>Econometrica: Journal of the Econometric Society</em>, 393–415.
</div>
<div id="ref-shi2016econometric" class="csl-entry">
Shi, Zhentao. 2016. <span>“Econometric Estimation with High-Dimensional Moment Equalities.”</span> <em>Journal of Econometrics</em> 195 (1): 104–19.
</div>
<div id="ref-shi2020high" class="csl-entry">
Shi, Zhentao, Liangjun Su, and Tian Xie. 2020. <span>“High Dimensional Forecast Combinations Under Latent Structures.”</span> <em>arXiv</em> 2010.09477.
</div>
<div id="ref-su2016identifying" class="csl-entry">
Su, Liangjun, Zhentao Shi, and Peter CB Phillips. 2016. <span>“Identifying Latent Structures in Panel Data.”</span> <em>Econometrica</em> 84 (6): 2215–64.
</div>
<div id="ref-theil1953repeated" class="csl-entry">
Theil, Henri. 1953. <span>“Repeated Least Squares Applied to Complete Equation Systems.”</span> <em>The Hague: Central Planning Bureau</em>.
</div>
<div id="ref-white1980heteroskedasticity" class="csl-entry">
White, Halbert. 1980. <span>“A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity.”</span> <em>Econometrica</em>, 817–38.
</div>
<div id="ref-white1996estimation" class="csl-entry">
———. 1996. <em>Estimation, Inference and Specification Analysis</em>. 22. Cambridge university press.
</div>
<div id="ref-white2014asymptotic" class="csl-entry">
———. 2000. <em>Asymptotic Theory for Econometricians</em>. Academic Press.
</div>
<div id="ref-working1927statistical" class="csl-entry">
Working, Elmer J. 1927. <span>“What Do Statistical "Demand Curves" Show?”</span> <em>The Quarterly Journal of Economics</em> 41 (2): 212–35.
</div>
<div id="ref-wright1928tariff" class="csl-entry">
Wright, Philip G. 1928. <em>Tariff on Animal and Vegetable Oils</em>. Macmillan Company, New York.
</div>
<div id="ref-young2005essentials" class="csl-entry">
Young, G Alastair, and Robert Leslie Smith. 2005. <em>Essentials of Statistical Inference</em>. Vol. 16. Cambridge University Press.
</div>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="endogeneity.html"><span class="header-section-number">11</span> Endogeneity</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#generalized-method-of-moments"><span class="header-section-number">12</span> Generalized Method of Moments</a></li>
<li>
<a class="nav-link" href="#instrumental-regression"><span class="header-section-number">12.1</span> Instrumental Regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#just-identification"><span class="header-section-number">12.1.1</span> Just-identification</a></li>
<li><a class="nav-link" href="#over-identification"><span class="header-section-number">12.1.2</span> Over-identification</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#gmm-estimator"><span class="header-section-number">12.2</span> GMM Estimator</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#efficient-gmm"><span class="header-section-number">12.2.1</span> Efficient GMM</a></li>
<li><a class="nav-link" href="#two-step-gmm"><span class="header-section-number">12.2.2</span> Two-Step GMM</a></li>
<li><a class="nav-link" href="#two-stage-least-squares"><span class="header-section-number">12.2.3</span> Two Stage Least Squares</a></li>
</ul>
</li>
<li><a class="nav-link" href="#gmm-in-nonlinear-model"><span class="header-section-number">12.3</span> GMM in Nonlinear Model</a></li>
<li><a class="nav-link" href="#summary-10"><span class="header-section-number">12.4</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/zhentaoshi/Econ5121A/blob/master/11-lecture.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/zhentaoshi/Econ5121A/edit/master/11-lecture.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Econ5121</strong>" was written by Zhentao Shi. It was last built on 2022-06-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
