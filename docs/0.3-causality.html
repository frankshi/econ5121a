<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="0.3 Causality | Regression, Projection and Causality" />
<meta property="og:type" content="book" />


<meta property="og:description" content="nothing" />


<meta name="author" content="Zhentao Shi" />

<meta name="date" content="2022-01-16" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="nothing">

<title>0.3 Causality | Regression, Projection and Causality</title>

<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface">Preface</a>
<ul>
<li><a href="personal-reflection.html#personal-reflection">Personal Reflection</a></li>
<li><a href="prerequisite.html#prerequisite">Prerequisite</a></li>
<li><a href="structure.html#structure">Structure</a></li>
<li><a href="packages.html#packages">Packages</a></li>
<li><a href="0.1-conditional-expectation.html#conditional-expectation"><span class="toc-section-number">0.1</span> Conditional Expectation</a></li>
<li><a href="0.2-linear-projection.html#linear-projection"><span class="toc-section-number">0.2</span> Linear Projection</a>
<ul>
<li><a href="0.2-linear-projection.html#omitted-variable-bias"><span class="toc-section-number">0.2.1</span> Omitted Variable Bias</a></li>
</ul></li>
<li><a href="0.3-causality.html#causality"><span class="toc-section-number">0.3</span> Causality</a>
<ul>
<li><a href="0.3-causality.html#structure-and-identification"><span class="toc-section-number">0.3.1</span> Structure and Identification</a></li>
<li><a href="0.3-causality.html#treatment-effect"><span class="toc-section-number">0.3.2</span> Treatment Effect</a></li>
<li><a href="0.3-causality.html#ate-and-cef"><span class="toc-section-number">0.3.3</span> ATE and CEF</a></li>
</ul></li>
<li><a href="0.4-summary.html#summary"><span class="toc-section-number">0.4</span> Summary</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="causality" class="section level2" number="0.3">
<h2><span class="header-section-number">0.3</span> Causality</h2>
<div id="structure-and-identification" class="section level3" number="0.3.1">
<h3><span class="header-section-number">0.3.1</span> Structure and Identification</h3>
<p>Unlike physical laws such as Einstein’s mass–energy equivalence
<span class="math inline">\(E=mc^{2}\)</span> and Newton’s universal gravitation <span class="math inline">\(F=Gm_{1}m_{2}/r^{2}\)</span>,
economic phenomena can rarely be summarized in such a minimalistic
style. When using experiments to verify physical laws, scientists often
manage to come up with smart design in which signal-to-noise ratio is so
high that small disturbances are kept at a negligible level. On the
contrary, economic laws do not fit a laboratory for experimentation.
What is worse, the subjects in economic studies — human beings — are
heterogeneous and with many features that are hard to control. People
from distinctive cultural and family backgrounds respond to the same
issue differently and researchers can do little to homogenize them. The
signal-to-noise ratios in economic laws are often significantly lower
than those of physical laws, mainly due to the lack of laboratory
setting and the heterogeneous nature of the subjects.</p>
<p>Educational return and the demand-supply system are two classical topics
in econometrics. A person’s incomes is determined by too many random
factors in the academic and career path that is impossible to
exhaustively observe and control. The observable prices and quantities
are outcomes of equilibrium so the demand and supply affect each other.</p>
<p>Generations of thinkers have been debating the definitions of causality.
In economics, an accepted definition is <em>structural causality</em>.
Structural causality is a thought experiment. It assumes that there is a
DGP that produces the observational data. If we can use data to recover
the DGP or some features of the DGP, then we have learned causality or
some implications of causality.</p>
<p>A key issue to resolve before looking at the realized sample is
<em>identification</em>. We say a model or DGP is <em>identified</em> if the each
possible parameter of the model under consideration generates
distinctive features of the observable data. A model is
<em>under-identified</em> if more than one parameter in the model can generate
exact the same features of the observable data. In other words, a model
is under-identified if from the observable data we cannot trace back to
a unique parameter in the model. A correctly specified model is the
prerequisite for any discussion of identification. In reality, all
models are wrong. Thus when talking about identification, we are
indulged in an imaginary world. If in such a thought experiment we still
cannot unique distinguish the true parameter of the data generating
process, then identification fails. We cannot determine what is the true
model no matter how large the sample is.</p>
</div>
<div id="treatment-effect" class="section level3" number="0.3.2">
<h3><span class="header-section-number">0.3.2</span> Treatment Effect</h3>
<p>We narrow down to the framework of the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>.
One question of particular interest is <em>treatment effect</em>. The treatment
effect is how much <span class="math inline">\(y\)</span> will change if we change a variable of interest,
say <span class="math inline">\(d\)</span>, by one unit while keeping all other variables (including the
unobservable variables) the same. The Latin phrase <em>ceteris paribus</em>
means “keep all other things constant.”</p>
<p>During the 2020 covid-19 pandemic, Hong Kong’s unemployment rate rose to
a high-level and consumption collapsed. In order to boost the economy,
some Hong Kong residents were qualified in receiving 10,000 HKD cash
allowance from the government. We are interested in learning how much
does the 10,000 HKD allowance increase people’s consumption. For an
individual, we imagine two parallel worlds: one with the cash allowance
and one without. The difference of the consumption in the world with the
allowance, denoted <span class="math inline">\(Y\left(1\right)\)</span>, and that in the world without the
allowance, denoted <span class="math inline">\(Y\left(0\right)\)</span>, is the treatment effect of that
particular person. This thought experiment is called the <em>potential
outcome framework</em>.</p>
<p>However, in reality one and only one scenario happens, which echoes the
saying of ancient Greek philosopher Heraclitus (553 BC--475 BC) “You
cannot step into the same river twice.” The individual treatment effect
is not operational (<em>operational</em> means it can be computed from data at
the population level), because one and only one outcome is realized.
With many people available, we can define <em>average treatment effect</em>
(ATE) as
<span class="math display">\[ATE=E\left[Y\left(1\right)-Y\left(0\right)\right]=E\left[Y\left(1\right)\right]-E\left[Y\left(0\right)\right].\]</span>
Notice that <span class="math inline">\(E\left[Y\left(1\right)\right]\)</span> and
<span class="math inline">\(E\left[Y\left(0\right)\right]\)</span> are still not operational before we
observe a companion variable
<span class="math display">\[D=1\left\{ \mbox{treatment received}\right\} .\]</span> Once each
individual’s treatment status is observable,
<span class="math inline">\(E\left[Y\left(1\right)|D=1\right]\)</span> and
<span class="math inline">\(E\left[Y\left(0\right)|D=0\right]\)</span> are operational from the data.</p>
<p>If the two potential outcomes
<span class="math inline">\(\left(Y\left(1\right),Y\left(0\right)\right)\)</span> are independent of the
assignment <span class="math inline">\(D\)</span>, then
<span class="math inline">\(E\left[Y\left(1\right)\right]=E\left[Y\left(1\right)|D=1\right]\)</span> and
<span class="math inline">\(E\left[Y\left(0\right)\right]=E\left[Y\left(0\right)|D=0\right]\)</span> so
that ATE can be estimated from the data in an operational way as
<span class="math display">\[ATE=E\left[Y\left(1\right)|D=1\right]-E\left[Y\left(0\right)|D=0\right].\]</span>
Therefore, to evaluate ATE ideally we would like use a lottery to
randomly decide that some people receive the treatment (<em>treatment
group</em>, with <span class="math inline">\(D=1\)</span>) and the others do not (<em>control group</em>, with <span class="math inline">\(D=0\)</span>).</p>
<p>When we have other control variables, we can also define a finer
treatment effect conditional on <span class="math inline">\(x\)</span>:
<span class="math display">\[ATE\left(x\right)=E\left[Y\left(1\right)|x\right]-E\left[Y\left(0\right)|x\right].\]</span>
ATE is the average effect in the population of individuals when we
hypothetical give them the treatment, keeping all other factors <span class="math inline">\(x\)</span>
constant. If conditioning on <span class="math inline">\(x\)</span>, the treatment <span class="math inline">\(D\)</span> is independent of
<span class="math inline">\(\left(Y\left(1\right),Y\left(0\right)\right)\)</span>, then ATE becomes
operational:
<span class="math display">\[ATE\left(x\right)=E\left[Y\left(1\right)|D=1,x\right]-E\left[Y\left(0\right)|D=0,x\right]\]</span>
The important condition
<span class="math inline">\(\left(\left(Y\left(1\right),Y\left(0\right)\right)\perp D\right)|x\)</span> is
called the <em>conditional independence assumption</em> (CIA).</p>
<p>CIA is more plausible than full independence. Consider the example
<span class="math inline">\(Y\left(1\right)=x+u\left(1\right)\)</span>, <span class="math inline">\(Y\left(0\right)=x+u\left(0\right)\)</span>
and <span class="math inline">\(D=1\left\{ x+u_{d}\geq0\right\}\)</span>. If
<span class="math inline">\(\left(\left(u\left(0\right),u\left(1\right)\right)\perp u_{d}\right)|x\)</span>,
then CIA is satisfied. Nevertheless
<span class="math inline">\(\left(Y\left(1\right),Y\left(0\right)\right)\)</span> and <span class="math inline">\(D\)</span> are statistically
dependent, since <span class="math inline">\(x\)</span> is involved in all random variables.</p>
</div>
<div id="ate-and-cef" class="section level3" number="0.3.3">
<h3><span class="header-section-number">0.3.3</span> ATE and CEF</h3>
<p>In the previous section the treatment <span class="math inline">\(D\)</span> is binary. Now we consider a
continuous treatment <span class="math inline">\(D\)</span>. Suppose the DGP, or the structural model, is
<span class="math inline">\(Y=h\left(D,x,u\right)\)</span> where <span class="math inline">\(D\)</span> and <span class="math inline">\(x\)</span> are observable and <span class="math inline">\(u\)</span> is
unobservable. It is natural to define ATE with the continuous treatment
(Hansen’s book Chapter 2.30 calls it <em>average causal effect</em>) as
<span class="math display">\[ATE\left(d,x\right)=E\left[\lim_{\Delta\to0}\frac{h\left(d+\Delta,x,u\right)-h\left(d,x,u\right)}{\Delta}\right]=E\left[\frac{\partial}{\partial d}h\left(d,x,u\right)\right],\]</span>
where the continuous differentiability of <span class="math inline">\(h\left(d,x,u\right)\)</span> at <span class="math inline">\(d\)</span>
is implicitly assumed. Unlike the binary treatment case, here <span class="math inline">\(d\)</span>
explicitly shows up in <span class="math inline">\(ATE\left(d,x\right)\)</span> because the effect can vary
at different values of <span class="math inline">\(d\)</span>. ATE here is the average effect in the
population of individuals if we hypothetical move <span class="math inline">\(D\)</span> a tiny bit around
<span class="math inline">\(d\)</span>, keeping all other factors <span class="math inline">\(x\)</span> constant.</p>
<p>In the previous sections, we focused on the CEF <span class="math inline">\(m\left(d,x\right)\)</span>,
where <span class="math inline">\(d\)</span> is added to <span class="math inline">\(x\)</span> as an additional variable of interest. We did
not intend to model the underlying economic mechanism
<span class="math inline">\(h\left(D,x,u\right)\)</span>, which may be very complex. Can we learn the
<span class="math inline">\(ATE\left(d,x\right)\)</span> which bears the structural causal interpretation,
from the mechanical <span class="math inline">\(m\left(d,x\right)\)</span> which merely cares about best
prediction? The answer is positive under CIA: <span class="math inline">\(\left(u\perp D\right)|x\)</span>.
<span class="math display">\[\begin{aligned}
\frac{\partial}{\partial d}m\left(d,x\right) &amp; =\frac{\partial}{\partial d}E\left[y|d,x\right]=\frac{\partial}{\partial d}E\left[h\left(d,x,u\right)|d,x\right]=\frac{\partial}{\partial d}\int h\left(d,x,u\right)f\left(u|d,x\right)du\\
 &amp; =\int\frac{\partial}{\partial d}\left[h\left(d,x,u\right)f\left(u|d,x\right)\right]du\\
 &amp; =\int\left[\frac{\partial}{\partial d}h\left(d,x,u\right)\right]f\left(u|d,x\right)du+\int h\left(d,x,u\right)\left[\frac{\partial}{\partial d}f\left(u|d,x\right)\right]du,\end{aligned}\]</span>
where the second line implicitly assumes interchangeability between the
integral and the partial derivative. Under CIA,
<span class="math inline">\(\frac{\partial}{\partial d}f\left(u|d,x\right)=0\)</span> and the second term
drops out. Thus
<span class="math display">\[\frac{\partial}{\partial d}m\left(d,x\right)=\int\left[\frac{\partial}{\partial d}h\left(d,x,u\right)\right]f\left(u|d,x\right)du=E\left[\frac{\partial}{\partial d}h\left(d,x,u\right)\right]=ATE\left(d,x\right).\]</span>
This is an important result. It says that if CIA holds, we can learn the
causal effect of <span class="math inline">\(d\)</span> on <span class="math inline">\(y\)</span> by the partial derivative of CEF conditional
on <span class="math inline">\(x\)</span>. In particular, if we further assume a linear CEF
<span class="math inline">\(m\left(d,x\right)=\beta_{d}d+\beta_{x}&#39;x\)</span>, then the causal effect is
the coefficient <span class="math inline">\(\beta_{d}\)</span>.</p>
<p>CIA is the key condition that links the CEF and the causal effect. CIA
is not an innocuous assumption. In applications, our causal results are
credible only when we can convincing defend CIA.</p>
<p>Let factories’ output be a Cobb-Douglas function
<span class="math inline">\(Y=AK^{\alpha}L^{\beta}\)</span>, where the capital level <span class="math inline">\(K\)</span> and labor <span class="math inline">\(L\)</span> as
well as the output <span class="math inline">\(Y\)</span> is observable, while the “technology” <span class="math inline">\(A\)</span> is
unobservable. Take logarithm on both sides of the equation:
<span class="math display">\[y=u+\alpha k+\beta l\label{eq:causal}\]</span> where <span class="math inline">\(y=\log Y\)</span>, <span class="math inline">\(u=\log A\)</span>,
<span class="math inline">\(k=\log K\)</span> and <span class="math inline">\(l=\log L\)</span>. Suppose <span class="math inline">\(\begin{pmatrix}u\\ k\\ l \end{pmatrix}\sim N\left(\begin{pmatrix}1\\ 1\\ 1 \end{pmatrix},\begin{pmatrix}1 &amp; 0.5 &amp; 0\\ 0.5 &amp; 1 &amp; 0\\ 0 &amp; 0 &amp; 1 \end{pmatrix}\right)\)</span> and <span class="math inline">\(\alpha=\beta=1/2\)</span> make the true DGP. Here <span class="math inline">\(u\)</span>
and <span class="math inline">\(k\)</span> are correlated, because factories of larger scale can afford
robots to facilitate automation.</p>
<ol style="list-style-type: decimal">
<li><p>What is the partial derivative of CEF when we use <span class="math inline">\(k\)</span> as a treatment
variable for a fixed labor level <span class="math inline">\(l\)</span>? (Hint: the CEF is a linear
function thanks to the joint normality.)</p></li>
<li><p>Does it coincide with <span class="math inline">\(\alpha=1/2\)</span>, the coefficient in the causal
model (<a href="#eq:causal" reference-type="ref" reference="eq:causal"><span class="math display">\[eq:causal\]</span></a>)? (Hint: No, because CIA is violated.)</p></li>
</ol>
<p>Sometimes applied researchers assume by brute force that
<span class="math inline">\(y=m\left(d,x\right)+u\)</span> is the DGP and <span class="math inline">\(E\left[u|d,x\right]=0\)</span>, where
<span class="math inline">\(d\)</span> is the variable of interest and <span class="math inline">\(x\)</span> is the vector of other control
variables. Under these assumptions,
<span class="math display">\[ATE\left(d,x\right)=E\left[\frac{\partial}{\partial d}\left(m\left(d,x\right)+u\right)|d,x\right]=\frac{\partial m\left(d,x\right)}{\partial d}+\frac{\partial}{\partial d}E\left[u|d,x\right]=\frac{\partial m\left(d,x\right)}{\partial d},\]</span>
where the second equality holds if
<span class="math inline">\(\frac{\partial}{\partial d}E\left[u|d,x\right]=E\left[\frac{\partial}{\partial d}u|d,x\right]\)</span>.
At a first glance, it seems that the mean independence assumption
<span class="math inline">\(E\left[u|d,x\right]=0\)</span>, which is weaker than CIA, implies the
equivalence between <span class="math inline">\(ATE\left(d,x\right)\)</span> and
<span class="math inline">\(\partial m\left(d,x\right)/\partial d\)</span> here. However, such slight
weakening is achieved by a very strong assumption that the DGP
<span class="math inline">\(h\left(d,x,u\right)\)</span> follows the additive separable form
<span class="math inline">\(m\left(d,x\right)+u\)</span>. Without economic theory to defend the choice of
the assumed DGP <span class="math inline">\(y=m\left(d,x\right)+u\)</span>, this is at best the
<em>reduced-form</em> approach.</p>
<p>The <em>structural approach</em> here models the economic mechanism, guided by
economic theory. The <em>reduced-form approach</em> is convenient and can
document stylized facts when suitable economic theory is not immediately
available. There are constant debates about the pros and cons of the two
approaches; see <em>Journal of Economic Perspectives</em> Vol. 24, No. 2 Spring
2010. In macroeconomics, the so-called Phillips curve, attributed to
A.W. Phillips about the negative correlation between inflation and
unemployment, is a stylized fact learned from the reduced-form approach.
The Lucas critique <span class="citation">(<a href="#ref-lucas1976econometric" role="doc-biblioref">Lucas 1976</a>)</span> exposed its lack of
microfoundation and advocated modeling deep parameters that are
invariant to policy changes. The latter is a structural approach.
Ironically, more than 40 years has passed since the Lucas critique,
equations with little microfoundation still dominate the analytical
apparatus of central bankers.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-lucas1976econometric" class="csl-entry">
Lucas, Robert E. 1976. <span>“Econometric Policy Evaluation: A Critique.”</span> In <em>Carnegie-Rochester Conference Series on Public Policy</em>, 1:19–46. 1.
</div>
</div>
<p style="text-align: center;">
<a href="0.2-linear-projection.html"><button class="btn btn-default">Previous</button></a>
<a href="0.4-summary.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
